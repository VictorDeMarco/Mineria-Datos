{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:left\" width=\"70%\" src=\"pics/escudo_COLOR_1L_DCHA.png\">\n",
    "<img style=\"float:right\" width=\"15%\" src=\"pics/PythonLogo.svg\">\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "# Minería de datos\n",
    "\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: navy; line-height: 1.3em; color: white; border-radius: 10px;\">Práctica Scikit-Learn 2</h2>\n",
    "\n",
    "## Docentes\n",
    "\n",
    " - Autor: José Francisco Diez Pastor\n",
    " - Juan José Rodríguez Diez\n",
    " \n",
    "## Estudiantes (1-2)\n",
    "\n",
    "- Victor De Marco\n",
    "- Alejandro Diez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de los datos\n",
    "\n",
    "Tenemos un dataset sintético sobre parkinson. El dataset está basado en un original creado por Rabie El Kharoua y disponible con licencia Creative Commons 4.0.\n",
    "\n",
    "Los atributos del dataset son:\n",
    "- Patient ID. Un identificador único del paciente, enteros del 3058 al 5152.\n",
    "------------\n",
    "- Age. La edad del paciente, entre 50 y 90 años.\n",
    "- Gender. El género del paciente 0-Hombre y 1-Mujer.\n",
    "- Ethnicity. La etnia del paciente codificada de la siguiente forma: 0-Caucasico, 1-Afroamericano, 2-Asiatico, 3-otro.\n",
    "- EducationLevel. Nivel educativo. Codificaciones: 0-Ninguno, 1-Secundaria, 2-Bachillerato, 3-Universidad.\n",
    "-------------\n",
    "- BMI: Índice de masa corporal. \n",
    "- Smoking: Indicador de fumador 0-No, 1-Si.\n",
    "- AlcoholConsumption: Consumo semanal de alcohol en unidades.\n",
    "- PhysicalActivity: Horas de actividad física a la semana.\n",
    "- DietQuality: Puntuación cuantitativa de calidad de dienta entre 0 y 10.\n",
    "- SleepQuality. Puntuación de calidad del sueño de 4 a 10.\n",
    "- FamilyHistoryParkinsons: Antecedentes familiares de la enfermedad 0-No, 1-Si\n",
    "- TraumaticBrainInjury: Historial de traumatismo cerebral 0-No, 1-Si.\n",
    "- Hypertension: Presencia de hipertensión 0-No, 1-Si.\n",
    "- Diabetes: Presencia de diabetes 0-No, 1-Si.\n",
    "- Depression: Presencia de depresión 0-No, 1-Si.\n",
    "- Stroke: Historial de ictus 0-No, 1-Si.\n",
    "-------------------------\n",
    "- SystolicBP: Presión sanguinea sistólica, en mmHg.\n",
    "- DiastolicBP: Presión sanguinea diastólica, en mmHg. \n",
    "- CholesterolTotal: Colesterol total, en mg/dL.\n",
    "- CholesterolLDL: Colesterol (Low-density lipoprotein), en mg/dL.\n",
    "- CholesterolHDL: Colesterol (High-density lipoprotein), en mg/dL.\n",
    "- CholesterolTriglycerides: Nivel de triglicéridos, en mg/dL.\n",
    "-----------------------------\n",
    "- MoCA: Montreal Cognitive Assessment score. Entre 0 y 30, valores bajos indican ranging from 0 to 30. Lower scores indicate deficit cognitivo.\n",
    "- FunctionalAssessment: Puntuación de la evaluación funcional. entre 0 y 10. Valores bajos indican mayor discapacidad. \n",
    "------------------------\n",
    "- Tremor: Presencia de temblores, 0-No, 1-Si.\n",
    "- Rigidity: Presencia de rigidez muscular, 0-No, 1-Si. \n",
    "- Bradykinesia: Presencia de bradicinesia (lentitud de movimientos), 0-No, 1-Si. \n",
    "- PosturalInstability: Presencia de inestabilidad postural, 0-No, 1-Si. \n",
    "- SpeechProblems: Presencia de problemas del habla, 0-No, 1-Si. \n",
    "- SleepDisorders: Presencia de desordenes del sueño, 0-No, 1-Si. \n",
    "- Constipation: Presencia de estreñimiento, 0-No, 1-Si. \n",
    "\n",
    "Clase\n",
    "\n",
    "- Diagnosis: Presencia de enfermedad de parkinson 0-No, 1-Si. \n",
    "\n",
    "--------------\n",
    "--------------\n",
    "\n",
    "Como la teoría a veces no funciona en la práctica, también hay 2 datasets sintéticos más sencillos, que se cargan desde un fichero serializado.\n",
    "\n",
    "- `X_sintetico_3d_50missing`. Es un conjunto de datos de 3 dimensiones, 100 filas. Los datos se corresponden con 2 círculos concéntricos en 3D, cada uno es de una clase diferente. Se han añadido missings en el 50% de las filas, solamente para probar la eficacia de los algoritmos de imputación de missings.\n",
    "- `X_sintetico_3d_extra_atts5`. Es un conjunto de datos de 3 dimensiones, 100 filas. Los datos se corresponden con 2 círculos concéntricos en 3D, cada uno es de una clase diferente. Se han añadido 5 atributos aleatorios. Solamente para probar la eficacia de los algoritmos de selección de atributos.\n",
    "- `y_sintetico`. Las clases de los datasets anteriores."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import pickle\n",
    "# Cargar los datos usando pickle.load\n",
    "with open(\".\"+os.sep+\"data\"+os.sep+\"datos.pkl\", \"rb\") as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "print(\"Datos cargados\")\n",
    "\n",
    "X_sintetico_3d_50missing = loaded_data[\"3d_50_missings\"]\n",
    "X_sintetico_3d_extra_atts5 = loaded_data[\"3d_5_extra_atts\"]\n",
    "y_sintetico = loaded_data[\"y_sintetico\"]\n",
    "\n",
    "display(X_sintetico_3d_extra_atts5[:5])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "'''\n",
    "Carga de los datos Parkinson\n",
    "'''\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(\".\"+os.sep+\"data\"+os.sep+\"data.csv\",index_col=0)\n",
    "\n",
    "display(df.head())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"index\"></a>\n",
    "## Tareas \n",
    "\n",
    "1. [Exploración de los datos. **(1 Punto)**](#1)\n",
    "2. [Tabla resumen y visualizaciones.**(1 Puntos)**](#2)\n",
    "3. [Validación cruzada propia.**(2 Puntos)**](#3)\n",
    "4. [Imputación de missings.**(2 Puntos)**](#4)\n",
    "5. [Selección de atributos.**(2 Puntos)**](#5)\n",
    "6. [Prueba otras cosas.**(2 Puntos)**](#6)\n",
    "\n",
    "-----------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tarea 1. Exploración de los datos. (1 Punto)<a id=\"1\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "\n",
    "Analiza el conjunto de datos.\n",
    "1. Número de filas y columnas.\n",
    "2. Proporción entre las clases.\n",
    "3. Proporción de nulos en los atributos. De más a menos nulos, los 20 primeros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**resultado esperado**\n",
    "\n",
    "```\n",
    "El dataset tiene 2105 filas y 42 columnas\n",
    "\n",
    "Si    61.95\n",
    "No    38.05\n",
    "Name: count, dtype: float64\n",
    "\n",
    "Stroke                        7.65\n",
    "PosturalInstability           7.41\n",
    "TraumaticBrainInjury          7.36\n",
    "Diabetes                      7.36\n",
    "Bradykinesia                  6.89\n",
    "Hypertension                  6.70\n",
    "Depression                    6.41\n",
    "FamilyHistoryParkinsons       6.03\n",
    "SleepDisorders                5.89\n",
    "Smoking                       5.75\n",
    "SpeechProblems                5.18\n",
    "Tremor                        4.42\n",
    "Gender                        4.18\n",
    "Constipation                  4.13\n",
    "Rigidity                      3.71\n",
    "Ethnicity                     3.42\n",
    "EducationLevel                2.23\n",
    "Age                           0.14\n",
    "DiastolicBP                   0.10\n",
    "AnnualHospitalizationsFake    0.00\n",
    "dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "filas, columnas = df.shape\n",
    "print(\"El dataset tiene {} filas y {} columnas\".format(filas, columnas), \"\\n\")\n",
    "\n",
    "proporcion = df[\"Diagnosis\"].value_counts(normalize=True) * 100\n",
    "proporcion = proporcion.round(2)\n",
    "proporcion = proporcion.rename(index={1: \"Si\", 0: \"No\"})\n",
    "print(proporcion, \"\\n\")\n",
    "\n",
    "proporcion_nulos = df.isnull().mean() * 100\n",
    "proporcion_nulos = proporcion_nulos.round(2)\n",
    "proporcion_nulos = proporcion_nulos.sort_values(ascending=False)\n",
    "print(proporcion_nulos.head(20))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tarea 2. Tabla resumen y visualizaciones. (1 Punto)<a id=\"2\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "1. Tabla resumen\n",
    "2. Grafica de barras.\n",
    "\n",
    "#### Tabla resumen\n",
    "Crea una tabla resumen que para cada atributo tenga:\n",
    "- %M. Porcentaje missings.\n",
    "- Un. Valores únicos (los DataFrame tienen un método `nunique`).\n",
    "- Min. Valor mínimo.\n",
    "- Max. Valor máximo.\n",
    "- Avg. Media.\n",
    "- Std. Desviación tipica.\n",
    "\n",
    "\n",
    "**resultado esperado**\n",
    "|                            |   %M |   Un. |           Min. |       Max. |         Avg. |        Std. |\n",
    "|:---------------------------|-----:|------:|---------------:|-----------:|-------------:|------------:|\n",
    "| PatientID                  | 0    |  2105 | 3058           | 5162       | 4110         |  607.805    |\n",
    "| Age                        | 0.14 |    40 |   50           |   89       |   69.5923    |   11.5937   |\n",
    "| Gender                     | 4.18 |     2 |    0           |    1       |    0.493803  |    0.500086 |\n",
    "| Ethnicity                  | 3.42 |     4 |    0           |    3       |    0.711756  |    1.01152  |\n",
    "| EducationLevel             | 2.23 |     4 |    0           |    3       |    1.33868   |    0.900208 |\n",
    "| BMI                        | 0    |  2105 |   15.0083      |   39.9999  |   27.2095    |    7.2081   |\n",
    "| Smoking                    | 5.75 |     2 |    0           |    1       |    0.306452  |    0.461136 |\n",
    "| AlcoholConsumption         | 0    |  2105 |    0.00222796  |   19.9889  |   10.0404    |    5.68701  |\n",
    "| PhysicalActivity           | 0    |  2105 |    0.00415669  |    9.99525 |    5.01667   |    2.89092  |\n",
    "| DietQuality                | 0    |  2105 |    1.05382e-05 |    9.99586 |    4.9129    |    2.87211  |\n",
    "| SleepQuality               | 0    |  2105 |    4.0005      |    9.99982 |    6.99664   |    1.75307  |\n",
    "| FamilyHistoryParkinsons    | 6.03 |     2 |    0           |    1       |    0.153691  |    0.360743 |\n",
    "| TraumaticBrainInjury       | 7.36 |     2 |    0           |    1       |    0.113846  |    0.317706 |\n",
    "| Hypertension               | 6.7  |     2 |    0           |    1       |    0.153259  |    0.360328 |\n",
    "| Diabetes                   | 7.36 |     2 |    0           |    1       |    0.157436  |    0.364305 |\n",
    "| Depression                 | 6.41 |     2 |    0           |    1       |    0.213706  |    0.410025 |\n",
    "| Stroke                     | 7.65 |     2 |    0           |    1       |    0.0529835 |    0.224058 |\n",
    "| SystolicBP                 | 0    |    90 |   90           |  179       |  133.72      |   26.5024   |\n",
    "| DiastolicBP                | 0.1  |    60 |   60           |  119       |   90.2649    |   17.0596   |\n",
    "| CholesterolTotal           | 0    |  2105 |  150.063       |  299.963   |  226.861     |   43.5894   |\n",
    "| CholesterolLDL             | 0    |  2105 |   50.0228      |  199.986   |  126.148     |   43.407    |\n",
    "| CholesterolHDL             | 0    |  2105 |   20.028       |   99.9823  |   59.6704    |   23.3709   |\n",
    "| CholesterolTriglycerides   | 0    |  2105 |   50.1136      |  399.975   |  222.94      |  101.896    |\n",
    "| MoCA                       | 0    |  2105 |    0.0211912   |   29.9701  |   15.0943    |    8.64301  |\n",
    "| FunctionalAssessment       | 0    |  2105 |    0.00150512  |    9.9927  |    4.98969   |    2.93388  |\n",
    "| Tremor                     | 4.42 |     2 |    0           |    1       |    0.434394  |    0.4958   |\n",
    "| Rigidity                   | 3.71 |     2 |    0           |    1       |    0.26147   |    0.439544 |\n",
    "| Bradykinesia               | 6.89 |     2 |    0           |    1       |    0.220408  |    0.414628 |\n",
    "| PosturalInstability        | 7.41 |     2 |    0           |    1       |    0.147768  |    0.354961 |\n",
    "| SpeechProblems             | 5.18 |     2 |    0           |    1       |    0.301102  |    0.458852 |\n",
    "| SleepDisorders             | 5.89 |     2 |    0           |    1       |    0.256436  |    0.436776 |\n",
    "| Constipation               | 4.13 |     2 |    0           |    1       |    0.303271  |    0.459785 |\n",
    "| LevodopaDailyDoseFake      | 0    |  2105 |    0.00113427  |    9.99008 |    4.98516   |    2.90696  |\n",
    "| MotorScoreFake             | 0    |   100 |    0           |   99       |   50.0052    |   28.8904   |\n",
    "| NonMotorScoreFake          | 0    |   100 |    0           |   99       |   48.7321    |   28.9259   |\n",
    "| AnnualHospitalizationsFake | 0    |     7 |    1           |    7       |    3.95107   |    2.01279  |\n",
    "| DailyStepCountFake         | 0    |  1694 | 1505           | 5998       | 3758.49      | 1295.43     |\n",
    "| SleepDurationFake          | 0    |  2105 |    3.00014     |    9.99834 |    6.57667   |    2.04185  |\n",
    "| CognitiveReactionTimeFake  | 0    |  2105 |    0.500512    |    4.99868 |    2.77361   |    1.32629  |\n",
    "| MedicationCountFake        | 0    |     8 |    0           |    7       |    3.49644   |    2.30166  |\n",
    "| DopamineLevelFake          | 0    |  2105 |    0.514678    |   14.9836  |    7.88379   |    4.13878  |\n",
    "| Diagnosis                  | 0    |     2 |    0           |    1       |    0.619477  |    0.485631 |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "resumen = pd.DataFrame(\n",
    "    {\n",
    "        \"%M\": df.isnull().mean() * 100,\n",
    "        \"Un\": df.nunique(),\n",
    "        \"Min\": df.min(numeric_only=True),\n",
    "        \"Max\": df.max(numeric_only=True),\n",
    "        \"Avg\": df.mean(numeric_only=True),\n",
    "        \"Std\": df.std(numeric_only=True),\n",
    "    }\n",
    ")\n",
    "display(resumen)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráfica de barras.\n",
    "\n",
    "1. Crea una tabla de contingencia Diagnosis (Diagnóstico) y Tremor (temblores).\n",
    "2. Crea un gráfico de barras agrupadas.\n",
    "3. (Si quieres investiga como poner título, ejes, etc)\n",
    "\n",
    "**resultado esperado**\n",
    "\n",
    "<img style=\"float:left\" width=\"70%\" src=\"pics/barras.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tabla de contingencia\n",
    "tabla = pd.crosstab(\n",
    "    df[\"Diagnosis\"], df[\"Tremor\"], rownames=[\"Parkinson\"], colnames=[\"Temblor\"]\n",
    ")\n",
    "tabla = tabla.rename(\n",
    "    index={0: \"Sin parkinson\", 1: \"Con parkinson\"},\n",
    "    columns={0: \"No\", 1: \"Si\"},\n",
    ")\n",
    "print(tabla)\n",
    "\n",
    "# Grafico de barras\n",
    "tabla.plot(kind='bar')\n",
    "plt.title(\"Relación entre Temblores y Diagnóstico de Parkinson\")\n",
    "plt.xlabel(\"Diagnóstico de Parkinson\")\n",
    "plt.ylabel(\"Número de pacientes\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tarea 3. Validación cruzada propia. (2 Puntos)<a id=\"3\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "Sklearn tiene una clase llamada `StratifiedKFold`, permite generar particiones train/test estratificadas (con la misma proporción entre clases que el conjunto de datos original).\n",
    "\n",
    "Esta clase permite que nos programemos nuestra propia validación cruzada.\n",
    "\n",
    "Veamos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X_toy = np.array([[1, 2], \n",
    "              [3, 4], \n",
    "              [5, 6], \n",
    "              [7, 8],\n",
    "              [9, 10],\n",
    "              [11, 12]])\n",
    "y_toy = np.array([0, 0, 0, 1, 1, 1])\n",
    "skf = StratifiedKFold(n_splits=3,random_state=0,shuffle=True)\n",
    "print(skf)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X_toy, y_toy)):\n",
    "    print(f\"\\nFold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    display(X_toy[train_index])\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    display(X_toy[test_index])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea las funciones:\n",
    "\n",
    "- `perform_experiment(X,y,method,n_folds)`: Recibe atributos, clase, algoritmo de clasificación y número de folds. Realiza la validación cruzada y almacena para cada fold las clases reales y las predicciones. Devuelve 2 listas, la lista de lista de valores de clase reales y la lista de lista de predicciones.\n",
    "- `evalua_predicciones(y_reales, y_predichas,metric_f)`: Aplica la función de calculo de métrica `metric_f` a todas las listas de valores reales y predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso:\n",
    "\n",
    "```Python\n",
    "y_reales, y_predichas = perform_experiment(X_iris,y_iris,KNeighborsClassifier(),10)\n",
    "print(len(y_reales)) # Es una lista de tamaño 10 porque he hecho 10 folds\n",
    "print(len(y_predichas)) # Es una lista de tamaño 10 porque he hecho 10 folds\n",
    "print(y_reales[0],y_predichas[0]) # Valores reales y predichos para las instancias de test del primer fold\n",
    "```\n",
    "\n",
    "```\n",
    "10\n",
    "10\n",
    "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2] [0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\"\"\"\n",
    "Pruebo con iris\n",
    "\"\"\"\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris[\"data\"]\n",
    "y_iris = iris[\"target\"]\n",
    "\n",
    "\n",
    "def perform_experiment(X, y, method, n_folds):\n",
    "    X = np.array(X).copy()\n",
    "    y = np.array(y).copy()\n",
    "    \n",
    "    reales = []\n",
    "    preds_list = []\n",
    "    skf = StratifiedKFold(n_splits=n_folds, random_state=0, shuffle=True)\n",
    "    for _, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        # Dividir en train y test\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Entrenar y predecir\n",
    "        method.fit(X_train, y_train)\n",
    "        preds = method.predict(X_test)\n",
    "        # Guardar resultados\n",
    "        reales.append(y_test)\n",
    "        preds_list.append(preds)\n",
    "    return reales, preds_list\n",
    "\n",
    "\n",
    "y_reales, y_predichas = perform_experiment(X_iris, y_iris, KNeighborsClassifier(), 10)\n",
    "print(len(y_reales))  # Es una lista de tamaño 10 porque he hecho 10 folds\n",
    "print(len(y_predichas))  # Es una lista de tamaño 10 porque he hecho 10 folds\n",
    "print(\n",
    "    y_reales[0], y_predichas[0]\n",
    ")  # Valores reales y predichos para las instancias de test del primer fold"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso:\n",
    "\n",
    "```Python\n",
    "tasas_de_acierto = evalua_predicciones(y_reales, y_predichas,accuracy_score)\n",
    "print(tasas_de_acierto) # 10 tasas de acierto, porque he hecho 10 folds\n",
    "print(tasas_de_acierto.mean()) # La media \n",
    "```\n",
    "\n",
    "```\n",
    "[1.         0.93333333 0.93333333 1.         0.93333333 0.93333333\n",
    " 0.93333333 1.         0.93333333 0.93333333]\n",
    "0.9533333333333334\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def evalua_predicciones(y_reales, y_predichas, metric_f):\n",
    "    return np.array(\n",
    "        [metric_f(y_reales[i], y_predichas[i]) for i in range(len(y_reales))]\n",
    "    )\n",
    "\n",
    "\n",
    "tasas_de_acierto = evalua_predicciones(y_reales, y_predichas, accuracy_score)\n",
    "print(tasas_de_acierto)  # 10 tasas de acierto, porque he hecho 10 folds\n",
    "print(tasas_de_acierto.mean())  # La media"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tarea 4. Imputación de missings. (2 Puntos)<a id=\"4\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea dos Pipelines para imputar los valores missing, uno de ellos para sustituir los missing por la media de ese atributo, el otro para sustituir los missings por el valor de ese atributo en el vecino más cercano.\n",
    "\n",
    "Prueba los pipelines con el conjunto de datos sintético y con el de parkinson.\n",
    "Pruebalo con varios clasificadores (cambiando el último paso del pipeline).\n",
    "\n",
    "\n",
    "Resultado esperado con `X_sintetico_3d_50missing`.\n",
    "\n",
    "-------\n",
    "```Python\n",
    "Pipeline(steps=[('imputer', SimpleImputer()), ('cls', KNeighborsClassifier())])\n",
    "Pipeline(steps=[('imputer', KNNImputer(n_neighbors=1)),\n",
    "                ('cls', KNeighborsClassifier())])\n",
    "\n",
    "Pipeline Imputer Mean - KNNClassifier: 0.58\n",
    "Pipeline Imputer KNN - KNNClassifier: 0.69\n",
    "```\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "'''\n",
    "Función proporcionada para dividir el DataFrame en atributos X y clase y.\n",
    "'''\n",
    "def split_att_target(df,target_name):\n",
    "    X = df.drop(target_name,axis=1).values\n",
    "    y = df[target_name].values\n",
    "    return X,y\n",
    "\n",
    "\n",
    "X, y = split_att_target(df,\"Diagnosis\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "datasets = [\n",
    "    (\"X_sintetico_3d_50missing\", X_sintetico_3d_50missing, y_sintetico),\n",
    "    (\"Parkinson\", *split_att_target(df, \"Diagnosis\")),\n",
    "]\n",
    "\n",
    "clasificadores = [\n",
    "    lambda: KNeighborsClassifier(),\n",
    "    lambda: RandomForestClassifier(),\n",
    "    lambda: SVC(),\n",
    "    lambda: DecisionTreeClassifier(),\n",
    "]\n",
    "\n",
    "for dataset_name, X, y in datasets:\n",
    "    print(f\"\\nDataset: {dataset_name}\")\n",
    "    for c in clasificadores:\n",
    "        pipeline_mean = Pipeline(\n",
    "            [(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"cls\", c())]\n",
    "        )\n",
    "        pipeline_knn = Pipeline([(\"imputer\", KNNImputer(n_neighbors=1)), (\"cls\", c())])\n",
    "        classifier_name = c().__class__.__name__\n",
    "\n",
    "        print(f\"    {pipeline_mean}\")\n",
    "        print(f\"    {pipeline_knn}\")\n",
    "\n",
    "        y_reales, y_predichas = perform_experiment(X, y, pipeline_mean, 10)\n",
    "        tasa_acierto = evalua_predicciones(y_reales, y_predichas, accuracy_score)\n",
    "        print(\n",
    "            f\"  - Pipeline Imputer Mean - {classifier_name}: {tasa_acierto.mean():.2f}\"\n",
    "        )\n",
    "        y_reales, y_predichas = perform_experiment(X, y, pipeline_knn, 10)\n",
    "        tasa_acierto = evalua_predicciones(y_reales, y_predichas, accuracy_score)\n",
    "        print(\n",
    "            f\"  - Pipeline Imputer KNN - {classifier_name}: {tasa_acierto.mean():.2f}\"\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tarea 5. Selección de atributos. (2 Puntos)<a id=\"5\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "\n",
    "Crea un Pipeline, que además del paso de imputación de missings haga selección de atributos usando un modelo (ExtraTreesClassifier).\n",
    "\n",
    "Pruebalo con los datos sintéticos y con los datos de Parkinson.\n",
    "\n",
    "Probado con `X_sintetico_3d_extra_atts5`\n",
    "\n",
    "```Python\n",
    "print(pipe_knn_attsel_cls)\n",
    "print(cls)\n",
    "\n",
    "\n",
    "print(\"KNNClassifier:\",acc_knn.round(2))\n",
    "print(\"Pipeline Att Sel - KNNClassifier:\",acc_attsel.round(2))\n",
    "```\n",
    "\n",
    "```\n",
    "Pipeline(steps=[('imputer_knn', KNNImputer(n_neighbors=1)),\n",
    "                ('att_sel',\n",
    "                 SelectFromModel(estimator=ExtraTreesClassifier(n_estimators=200))),\n",
    "                ('cls', KNeighborsClassifier())])\n",
    "KNeighborsClassifier()\n",
    "KNNClassifier: 0.62\n",
    "Pipeline Att Sel - KNNClassifier: 1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "datasets = [\n",
    "    (\"X_sintetico_3d_50missing\", X_sintetico_3d_extra_atts5, y_sintetico),\n",
    "    (\"Parkinson\", *split_att_target(df, \"Diagnosis\")),\n",
    "]\n",
    "\n",
    "for dataset_name, X, y in datasets:\n",
    "    print(f\"\\nDataset: {dataset_name}\")\n",
    "    pipeline_knn = Pipeline(\n",
    "        [\n",
    "            (\"imputer\", KNNImputer(n_neighbors=1)),\n",
    "            (\"cls\", KNeighborsClassifier()),\n",
    "        ]\n",
    "    )\n",
    "    pipeline_knn_att = Pipeline(\n",
    "        [\n",
    "            (\"imputer\", KNNImputer(n_neighbors=1)),\n",
    "            (\n",
    "                \"att_sel\",\n",
    "                SelectFromModel(estimator=ExtraTreesClassifier(n_estimators=200)),\n",
    "            ),\n",
    "            (\"cls\", KNeighborsClassifier()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"    {pipeline_knn}\")\n",
    "    print(f\"    {pipeline_knn_att}\")\n",
    "\n",
    "    y_reales, y_predichas = perform_experiment(X, y, pipeline_knn, 10)\n",
    "    tasa_acierto = evalua_predicciones(y_reales, y_predichas, accuracy_score)\n",
    "    y_reales, y_predichas = perform_experiment(X, y, pipeline_knn_att, 10)\n",
    "    tasa_acierto_att = evalua_predicciones(y_reales, y_predichas, accuracy_score)\n",
    "    print(f\"KNNClassifier: {tasa_acierto.mean():.2f}\")\n",
    "    print(f\"Pipeline Att Sel - KNNClassifier: {tasa_acierto_att.mean():.2f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tarea 6. Prueba otras cosas. (2 Puntos)<a id=\"6\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "Prueba otros clasificadores aparte de KNN.\n",
    "Prueba otras transformaciones de los datos en los Pipelines, por ejemplo Standarizar los datos.\n",
    "Optimiza clasificadores, por ejemplo usando GridSearch o RandomSearch\n",
    "Haz una tabla comparativa.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T12:54:40.632079Z",
     "start_time": "2025-03-21T12:53:52.918850Z"
    }
   },
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "datasets = [\n",
    "    (\"X_sintetico_3d_50missing\", X_sintetico_3d_extra_atts5, y_sintetico),\n",
    "    (\"Parkinson\", *split_att_target(df, \"Diagnosis\")),\n",
    "]\n",
    "clasificadores = [\n",
    "    lambda: RandomForestClassifier(),\n",
    "    lambda: SVC(),\n",
    "    lambda: DecisionTreeClassifier(),\n",
    "]\n",
    "\n",
    "parameter_por_modelo = {\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"cls__n_estimators\": [100, 200, 300],\n",
    "        \"cls__max_depth\": [None, 10, 20],\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"cls__C\": [0.1, 1, 10],\n",
    "        \"cls__kernel\": [\"linear\", \"rbf\"],\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"cls__max_depth\": [None, 10, 20],\n",
    "        \"cls__criterion\": [\"gini\", \"entropy\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for dataset_name, X, y in datasets:\n",
    "    print(f\"\\nDataset: {dataset_name}\")\n",
    "    for c in clasificadores:\n",
    "        pipelineS = Pipeline(\n",
    "            [\n",
    "                (\"impute\", KNNImputer(n_neighbors=1)),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"cls\", c()),\n",
    "            ]\n",
    "        )\n",
    "        pipelineM = Pipeline(\n",
    "            [\n",
    "                (\"impute\", KNNImputer(n_neighbors=1)),\n",
    "                (\"scaler\", MinMaxScaler()),\n",
    "                (\"cls\", c()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        classifier_name = c().__class__.__name__\n",
    "        print(f\"    {pipelineS}\")\n",
    "        print(f\"    {pipelineM}\")\n",
    "\n",
    "        y_reales, y_predichas = perform_experiment(X, y, pipelineS, 10)\n",
    "        tasa_aciertoS = evalua_predicciones(y_reales, y_predichas, accuracy_score)\n",
    "        y_reales, y_predichas = perform_experiment(X, y, pipelineM, 10)\n",
    "        tasa_aciertoM = evalua_predicciones(y_reales, y_predichas, accuracy_score)\n",
    "        print(\n",
    "            f\"  - Pipeline scaler Standard - {classifier_name}: {tasa_aciertoS.mean():.2f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"  - Pipeline scaler MinMax - {classifier_name}: {tasa_aciertoM.mean():.2f}\"\n",
    "        )\n",
    "        param_grid = parameter_por_modelo.get(classifier_name, {})\n",
    "        grid_searchS = GridSearchCV(pipelineS, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "        grid_searchM = GridSearchCV(pipelineM, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "        grid_searchS.fit(X, y)\n",
    "        grid_searchM.fit(X, y)\n",
    "        print(f\"Mejor modelo para {classifier_name} con Standard scaler: {grid_searchS.best_params_}\")\n",
    "        print(f\"Mejor modelo para {classifier_name} con MinMax scaler: {grid_searchM.best_params_}\")\n",
    "        # Guardar resultados en la lista\n",
    "        resultados.append([dataset_name, classifier_name, \"StandardScaler\", tasa_aciertoS.mean(), grid_searchS.best_params_])\n",
    "        resultados.append([dataset_name, classifier_name, \"MinMaxScaler\", tasa_aciertoM.mean(), grid_searchM.best_params_])\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df_resultados = pd.DataFrame(resultados, columns=[\"Dataset\", \"Clasificador\", \"Scaler\", \"Accuracy\", \"Best Params\"])\n",
    "\n",
    "# Mostrar tabla ordenada por dataset y accuracy descendente\n",
    "df_resultados = df_resultados.sort_values(by=[\"Dataset\", \"Accuracy\"], ascending=[True, False])\n",
    "\n",
    "# Imprimir tabla\n",
    "print(df_resultados)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: X_sintetico_3d_50missing\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('cls', RandomForestClassifier())])\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', MinMaxScaler()), ('cls', RandomForestClassifier())])\n",
      "  - Pipeline scaler Standard - RandomForestClassifier: 0.90\n",
      "  - Pipeline scaler MinMax - RandomForestClassifier: 0.93\n",
      "Mejor modelo para RandomForestClassifier con Standard scaler: {'cls__max_depth': None, 'cls__n_estimators': 200}\n",
      "Mejor modelo para RandomForestClassifier con MinMax scaler: {'cls__max_depth': None, 'cls__n_estimators': 300}\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', StandardScaler()), ('cls', SVC())])\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', MinMaxScaler()), ('cls', SVC())])\n",
      "  - Pipeline scaler Standard - SVC: 0.56\n",
      "  - Pipeline scaler MinMax - SVC: 0.74\n",
      "Mejor modelo para SVC con Standard scaler: {'cls__C': 10, 'cls__kernel': 'rbf'}\n",
      "Mejor modelo para SVC con MinMax scaler: {'cls__C': 10, 'cls__kernel': 'rbf'}\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('cls', DecisionTreeClassifier())])\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', MinMaxScaler()), ('cls', DecisionTreeClassifier())])\n",
      "  - Pipeline scaler Standard - DecisionTreeClassifier: 0.98\n",
      "  - Pipeline scaler MinMax - DecisionTreeClassifier: 0.98\n",
      "Mejor modelo para DecisionTreeClassifier con Standard scaler: {'cls__criterion': 'gini', 'cls__max_depth': 20}\n",
      "Mejor modelo para DecisionTreeClassifier con MinMax scaler: {'cls__criterion': 'gini', 'cls__max_depth': None}\n",
      "\n",
      "Dataset: Parkinson\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('cls', RandomForestClassifier())])\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', MinMaxScaler()), ('cls', RandomForestClassifier())])\n",
      "  - Pipeline scaler Standard - RandomForestClassifier: 0.78\n",
      "  - Pipeline scaler MinMax - RandomForestClassifier: 0.77\n",
      "Mejor modelo para RandomForestClassifier con Standard scaler: {'cls__max_depth': 10, 'cls__n_estimators': 300}\n",
      "Mejor modelo para RandomForestClassifier con MinMax scaler: {'cls__max_depth': 20, 'cls__n_estimators': 300}\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', StandardScaler()), ('cls', SVC())])\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', MinMaxScaler()), ('cls', SVC())])\n",
      "  - Pipeline scaler Standard - SVC: 0.74\n",
      "  - Pipeline scaler MinMax - SVC: 0.75\n",
      "Mejor modelo para SVC con Standard scaler: {'cls__C': 10, 'cls__kernel': 'linear'}\n",
      "Mejor modelo para SVC con MinMax scaler: {'cls__C': 1, 'cls__kernel': 'rbf'}\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('cls', DecisionTreeClassifier())])\n",
      "    Pipeline(steps=[('impute', KNNImputer(n_neighbors=1)),\n",
      "                ('scaler', MinMaxScaler()), ('cls', DecisionTreeClassifier())])\n",
      "  - Pipeline scaler Standard - DecisionTreeClassifier: 0.69\n",
      "  - Pipeline scaler MinMax - DecisionTreeClassifier: 0.68\n",
      "Mejor modelo para DecisionTreeClassifier con Standard scaler: {'cls__criterion': 'entropy', 'cls__max_depth': 10}\n",
      "Mejor modelo para DecisionTreeClassifier con MinMax scaler: {'cls__criterion': 'entropy', 'cls__max_depth': 10}\n",
      "                     Dataset            Clasificador          Scaler  \\\n",
      "6                  Parkinson  RandomForestClassifier  StandardScaler   \n",
      "7                  Parkinson  RandomForestClassifier    MinMaxScaler   \n",
      "9                  Parkinson                     SVC    MinMaxScaler   \n",
      "8                  Parkinson                     SVC  StandardScaler   \n",
      "10                 Parkinson  DecisionTreeClassifier  StandardScaler   \n",
      "11                 Parkinson  DecisionTreeClassifier    MinMaxScaler   \n",
      "4   X_sintetico_3d_50missing  DecisionTreeClassifier  StandardScaler   \n",
      "5   X_sintetico_3d_50missing  DecisionTreeClassifier    MinMaxScaler   \n",
      "1   X_sintetico_3d_50missing  RandomForestClassifier    MinMaxScaler   \n",
      "0   X_sintetico_3d_50missing  RandomForestClassifier  StandardScaler   \n",
      "3   X_sintetico_3d_50missing                     SVC    MinMaxScaler   \n",
      "2   X_sintetico_3d_50missing                     SVC  StandardScaler   \n",
      "\n",
      "    Accuracy                                        Best Params  \n",
      "6   0.780020   {'cls__max_depth': 10, 'cls__n_estimators': 300}  \n",
      "7   0.774347   {'cls__max_depth': 20, 'cls__n_estimators': 300}  \n",
      "9   0.750088                {'cls__C': 1, 'cls__kernel': 'rbf'}  \n",
      "8   0.743904            {'cls__C': 10, 'cls__kernel': 'linear'}  \n",
      "10  0.685994  {'cls__criterion': 'entropy', 'cls__max_depth'...  \n",
      "11  0.681733  {'cls__criterion': 'entropy', 'cls__max_depth'...  \n",
      "4   0.980000   {'cls__criterion': 'gini', 'cls__max_depth': 20}  \n",
      "5   0.980000  {'cls__criterion': 'gini', 'cls__max_depth': N...  \n",
      "1   0.930000  {'cls__max_depth': None, 'cls__n_estimators': ...  \n",
      "0   0.900000  {'cls__max_depth': None, 'cls__n_estimators': ...  \n",
      "3   0.740000               {'cls__C': 10, 'cls__kernel': 'rbf'}  \n",
      "2   0.560000               {'cls__C': 10, 'cls__kernel': 'rbf'}  \n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
