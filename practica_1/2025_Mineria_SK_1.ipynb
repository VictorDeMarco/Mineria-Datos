{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:left\" width=\"70%\" src=\"pics/escudo_COLOR_1L_DCHA.png\">\n",
    "<img style=\"float:right\" width=\"15%\" src=\"pics/PythonLogo.svg\">\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "# Minería de datos\n",
    "\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: navy; line-height: 1.3em; color: white; border-radius: 10px;\">Práctica Scikit-Learn 1</h2>\n",
    "\n",
    "## Docentes\n",
    "\n",
    " - Autor: José Francisco Diez Pastor\n",
    " - Juan José Rodríguez Diez\n",
    " \n",
    "## Estudiantes (1-2)\n",
    "\n",
    "- Victor De Marco\n",
    "- Alejandro Diez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de los datos\n",
    "\n",
    "### **Introducción al Conjunto de Datos: Cleveland Heart Disease**  \n",
    "\n",
    "El conjunto de datos **Cleveland Heart Disease** es ampliamente utilizado en estudios de predicción de enfermedades cardíacas. Contiene información clínica de 300 individuos y se emplea para analizar la presencia y severidad de enfermedades del corazón.  \n",
    "\n",
    "Este conjunto de datos incluye **14 columnas**. Cada columna representa diferentes variables médicas y factores de riesgo asociados a enfermedades cardiovasculares.  \n",
    "\n",
    "### **Descripción de las Variables**  \n",
    "\n",
    "- **Edad** (*Age*): Indica la edad del individuo.  \n",
    "- **Sexo** (*Sex*): Género del individuo, donde:  \n",
    "  - 1 = Hombre  \n",
    "  - 0 = Mujer  \n",
    "- **Tipo de dolor torácico** (*Chest-pain type*): Clasificación del tipo de dolor en el pecho:  \n",
    "  - 1 = Angina típica  \n",
    "  - 2 = Angina atípica  \n",
    "  - 3 = Dolor no anginoso  \n",
    "  - 4 = Asintomático  \n",
    "- **Presión arterial en reposo** (*Resting Blood Pressure*): Valor de la presión arterial en reposo del individuo, medido en mmHg.  \n",
    "- **Colesterol en sangre** (*Serum Cholesterol*): Nivel de colesterol sérico en mg/dl.  \n",
    "- **Glucemia en ayunas** (*Fasting Blood Sugar*): Indica si el nivel de azúcar en sangre en ayunas es superior a 120 mg/dl:  \n",
    "  - 1 = Sí (mayor a 120 mg/dl)  \n",
    "  - 0 = No (menor o igual a 120 mg/dl)  \n",
    "- **Electrocardiograma en reposo** (*Resting ECG*): Clasificación del resultado del ECG en reposo:  \n",
    "  - 0 = Normal  \n",
    "  - 1 = Anormalidad en la onda ST-T  \n",
    "  - 2 = Hipertrofia ventricular izquierda  \n",
    "- **Frecuencia cardíaca máxima alcanzada** (*Max heart rate achieved*): Frecuencia cardíaca máxima registrada durante el ejercicio.  \n",
    "- **Angina inducida por el ejercicio** (*Exercise induced angina*): Indica si el individuo experimentó angina durante el ejercicio:  \n",
    "  - 1 = Sí  \n",
    "  - 0 = No  \n",
    "- **Depresión del segmento ST inducida por el ejercicio en relación con el reposo** (*ST depression induced by exercise relative to rest*): Valor de depresión del segmento ST, que puede ser un número entero o decimal.  \n",
    "- **Segmento ST en el ejercicio máximo** (*Peak exercise ST segment*): Clasificación de la pendiente del segmento ST durante el ejercicio:  \n",
    "  - 1 = Ascendente  \n",
    "  - 2 = Plano  \n",
    "  - 3 = Descendente  \n",
    "- **Número de vasos principales coloreados por fluoroscopia** (*Number of major vessels (0-3) colored by fluoroscopy*): Número de vasos principales observados mediante fluoroscopia, representado como un número entero o decimal.  \n",
    "- **Talasemia** (*Thal*): Indica la presencia de talasemia:  \n",
    "  - 3 = Normal  \n",
    "  - 6 = Defecto fijo  \n",
    "  - 7 = Defecto reversible  \n",
    "- **Diagnóstico de enfermedad cardíaca** (*Diagnosis of heart disease*): Variable objetivo que indica la presencia de una enfermedad cardíaca:  \n",
    "  - 0 = Ausencia de enfermedad  \n",
    "  - 1, 2, 3, 4 = Presencia de enfermedad (varios niveles, según la gravedad)  \n",
    "\n",
    "Este conjunto de datos es útil tanto para clasificación (clasificando los niveles o Ausencia / Presencia de la enfermedad) como para regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"index\"></a>\n",
    "## Tareas \n",
    "\n",
    "1. [Cargar y explorar superficialmente los datos. **(2 Punto)**](#1)\n",
    "2. [Creación de una función para evaluar clasificadores.**(2.5 Puntos)**](#2)\n",
    "4. [Experimentos con clasificadores. **(2.5 Puntos)**](#4)\n",
    "5. [Análisis de resultados. **(3 Puntos)**](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tarea 1. Cargar y explorar superficialmente los datos. (2 Punto)<a id=\"1\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "\n",
    "Realizar 3 funciones, con su documentación.\n",
    "- `carga_datos(url)`.   Recibe la url (que puede ser la ruta local a un fichero) y devuelve $X$ un array 2D de tamaño número de ejemplos $\\times$ número de atributos e $y$ un array formado por tantos valores como ejemplos.\n",
    "- `binariza_clase(y)`.  Recibe un array con valores de 1 al 5 y devuelve otro array con valores 0 y 1. El 0 es para los casos asintomáticos y el 1 para el resto de casos.\n",
    "- `cuenta_valores_clase(y)`. Recibe un array de una dimensión y múltiples valores y devuelve un diccionario que asocia cada clase diferente con el número de veces que aparece.\n",
    "\n",
    "Pista: Se puede hacer una copia profunda de un array de numpy con el método `copy`. Por ejemplo:\n",
    "```Python\n",
    "y_2c = y.copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-02-27T16:13:14.037712Z",
     "start_time": "2025-02-27T16:13:14.024213Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def carga_datos(url: str):\n",
    "    \"\"\"\n",
    "    Cargar los datos desde un archivo CSV. La última columna se considera la clase. Las columnas anteriores son las características.\n",
    "\n",
    "    Args:\n",
    "        url (str): Path al archivo CSV.\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[list[float]], list[int]]: Matriz de características (filas: muestras, columnas: características) y vector de clases.\n",
    "    \"\"\"\n",
    "\n",
    "    # Lee los datos desde un archivo CSV\n",
    "    data = pd.read_csv(url)\n",
    "\n",
    "    X = data.iloc[:, :-1].values  # Todas las columnas excepto la última\n",
    "    y = data.iloc[:, -1].values  # La última columna\n",
    "    return (X, y)\n",
    "\n",
    "\n",
    "def binariza_clase(y):\n",
    "    \"\"\"\n",
    "    Binariza la clase, convirtiendo los valores en 0 y 1. Si la clase es 0, se convierte en 0, si es distinto de 0, se\n",
    "    convierte en 1.\n",
    "\n",
    "    Args:\n",
    "        y (list[int]): Vector de clases.\n",
    "\n",
    "    Returns:\n",
    "        list[int]: Vector de clases binarizado.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Recorrer la lista de clases y binarizarlas\n",
    "    return np.array([0 if clase == 0 else 1 for clase in y])\n",
    "\n",
    "\n",
    "def cuenta_valores_clase(y):\n",
    "    \"\"\"\n",
    "    Se cuentan las cantidades de clases en el vector de clases.\n",
    "\n",
    "    Args:\n",
    "        y (list[int]): Vector de clases.\n",
    "\n",
    "    Returns:\n",
    "        dict[int, int]: Diccionario con la cantidad de cada clase.\n",
    "    \"\"\"\n",
    "\n",
    "    count = {}\n",
    "    for val in y:\n",
    "        # Si el valor ya está en el diccionario, se incrementa en 1, si no, se crea con valor 1\n",
    "        if val in count:\n",
    "            count[val] += 1\n",
    "        else:\n",
    "            count[int(val)] = 1\n",
    "    return count\n",
    "\n",
    "\n",
    "# Mostrar las primeras filas de X e y\n",
    "X, y = carga_datos(\"./data/HeartDisease.csv\")\n",
    "\n",
    "display(X[:5])\n",
    "display(y[:50])\n",
    "\n",
    "# Mostrar la binarización de la clase\n",
    "y_bin = binariza_clase(y)\n",
    "\n",
    "display(y_bin[:50])\n",
    "\n",
    "# Contar los valores de la clase\n",
    "y_count = cuenta_valores_clase(y)\n",
    "y_bin_count = cuenta_valores_clase(y_bin)\n",
    "\n",
    "display(y_count)\n",
    "display(y_bin_count)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0. ,  63. ,   1. ,   1. , 145. , 233. ,   1. ,   2. , 150. ,\n",
       "          0. ,   2.3,   3. ,   0. ,   6. ],\n",
       "       [  1. ,  67. ,   1. ,   4. , 160. , 286. ,   0. ,   2. , 108. ,\n",
       "          1. ,   1.5,   2. ,   3. ,   3. ],\n",
       "       [  2. ,  67. ,   1. ,   4. , 120. , 229. ,   0. ,   2. , 129. ,\n",
       "          1. ,   2.6,   2. ,   2. ,   7. ],\n",
       "       [  3. ,  37. ,   1. ,   3. , 130. , 250. ,   0. ,   0. , 187. ,\n",
       "          0. ,   3.5,   3. ,   0. ,   3. ],\n",
       "       [  4. ,  41. ,   0. ,   2. , 130. , 204. ,   0. ,   2. , 172. ,\n",
       "          0. ,   1.4,   1. ,   0. ,   3. ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 0, 0, 3, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 3, 4, 0, 0, 0, 0, 3, 0, 2, 1, 0, 0, 0, 3, 1, 3, 0, 4, 0, 0, 0,\n",
       "       1, 4, 0, 4, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: 164, 2: 36, 1: 55, 3: 35, 4: 13}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: 164, 1: 139}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado esperado es:\n",
    "\n",
    "```\n",
    "array([[  0. ,  63. ,   1. ,   1. , 145. , 233. ,   1. ,   2. , 150. ,\n",
    "          0. ,   2.3,   3. ,   0. ,   6. ],\n",
    "       [  1. ,  67. ,   1. ,   4. , 160. , 286. ,   0. ,   2. , 108. ,\n",
    "          1. ,   1.5,   2. ,   3. ,   3. ],\n",
    "       [  2. ,  67. ,   1. ,   4. , 120. , 229. ,   0. ,   2. , 129. ,\n",
    "          1. ,   2.6,   2. ,   2. ,   7. ],\n",
    "       [  3. ,  37. ,   1. ,   3. , 130. , 250. ,   0. ,   0. , 187. ,\n",
    "          0. ,   3.5,   3. ,   0. ,   3. ],\n",
    "       [  4. ,  41. ,   0. ,   2. , 130. , 204. ,   0. ,   2. , 172. ,\n",
    "          0. ,   1.4,   1. ,   0. ,   3. ]])\n",
    "\n",
    "array([0, 2, 1, 0, 0, 0, 3, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       1, 3, 4, 0, 0, 0, 0, 3, 0, 2, 1, 0, 0, 0, 3, 1, 3, 0, 4, 0, 0, 0,\n",
    "       1, 4, 0, 4, 0, 0])\n",
    "\n",
    "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
    "       1, 1, 0, 1, 0, 0])\n",
    "\n",
    "{0: 164, 2: 36, 1: 55, 3: 35, 4: 13}\n",
    "{0: 164, 1: 139}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2. Creación de una función para evaluar clasificadores. (2.5 Puntos)<a id=\"2\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "Crear y documentar las funciones: \n",
    "- `evalua(X,y,clasificador,n_folds)`\n",
    "    Evalua el clasificador indicado, usando el número de folds indicado, los atributos $X$ y la clase $y$. \n",
    "    - Devuelve 3 valores: accuracy_score, precision_score y recall_score.\n",
    " \n",
    "- `predicciones(X,y,clasificador,n_folds)` Obtiene las predicciones del clasificador indicado, usando el número de folds indicado, los atributos $X$ y la clase $y$. Devuelve predicciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "print(evalua(X,y,KNeighborsClassifier(),10))\n",
    "print(predicciones(X,y,KNeighborsClassifier(),10)[:10])\n",
    "```\n",
    "\n",
    "```\n",
    "(0.5577557755775577, 0.5185185185185185, 0.5035971223021583)\n",
    "[0 1 0 0 0 0 0 1 0 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T15:16:44.441974Z",
     "start_time": "2025-02-27T15:16:44.384673Z"
    }
   },
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def predicciones(\n",
    "    X: list[list[float]], y: list[int], clasificador: BaseEstimator, n_folds: int\n",
    ") -> list[int]:\n",
    "    \"\"\"\n",
    "    Realiza predicciones mediante validación cruzada.\n",
    "\n",
    "    Args:\n",
    "        X (list[list[float]]): Matriz de características.\n",
    "        y (list[int]): Vector de clases.\n",
    "        clasificador (BaseEstimator): Clasificador a utilizar.\n",
    "        n_folds (int): Número de particiones para la validación cruzada.\n",
    "\n",
    "    Returns:\n",
    "        list[int]: Vector de predicciones.\n",
    "    \"\"\"\n",
    "    return cross_val_predict(clasificador, X, y, cv=n_folds)\n",
    "\n",
    "\n",
    "def evalua(\n",
    "    X: list[list[float]], y: list[int], clasificador: BaseEstimator, n_folds: int\n",
    ") -> tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Evalúa el clasificador mediante validación cruzada.\n",
    "\n",
    "    Args:\n",
    "        X (list[list[float]]): Matriz de características.\n",
    "        y (list[int]): Vector de clases.\n",
    "        clasificador (BaseEstimator): Clasificador a utilizar.\n",
    "        n_folds (int): Número de particiones para la validación cruzada.\n",
    "\n",
    "    Returns:\n",
    "        tuple[float, float, float]: Accuracy, precisión y recall.\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = predicciones(X, y, clasificador, n_folds)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    return (accuracy, precision, recall)\n",
    "\n",
    "\n",
    "\n",
    "print(evalua(X, y_bin, KNeighborsClassifier(), 10))\n",
    "print(predicciones(X, y_bin, KNeighborsClassifier(), 10)[:10])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5577557755775577, 0.5185185185185185, 0.5035971223021583)\n",
      "[0 1 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3. Experimentos con clasificadores. (2.5 Puntos)<a id=\"4\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar la función anterior `evalua` con varios clasificadores de los disponibles en SkLearn, usando por lo menos los 5 clasificadores siguientes:\n",
    "- Regresión Logística\n",
    "- Random Forest\n",
    "- KNN\n",
    "- SVC (SVM Classifier)\n",
    "- Arbol de Decisión.\n",
    "\n",
    "Busca el mejor en accuracy, precision y recall.\n",
    "\n",
    "Investiga un poco los parámetros de los algoritmos que funcionen mejor para cada uno de las medidas. Prueba cambios en los parámetros por defecto.\n",
    "\n",
    "Ejemplo\n",
    "```\n",
    "KNN\n",
    "Tasa de acierto 0.5578, Precision 0.5185, Recall 0.5036\n",
    "Regresion logistica\n",
    "Tasa de acierto 0.8383, Precision 0.8462, Recall 0.7914\n",
    "Random Forest\n",
    "Tasa de acierto 0.8449, Precision 0.8594, Recall 0.7914\n",
    "SVC\n",
    "Tasa de acierto 0.6436, Precision 0.6782, Recall 0.4245\n",
    "Decision Tree\n",
    "Tasa de acierto 0.7657, Precision 0.7429, Recall 0.7482\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T15:16:07.710152Z",
     "start_time": "2025-02-27T15:16:04.479701Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "k_neighbors = evalua(X, y_bin, KNeighborsClassifier(), 10)\n",
    "logistic_regression = evalua(X, y_bin, LogisticRegression(max_iter=2000), 10)\n",
    "random_forest = evalua(X, y_bin, RandomForestClassifier(), 10)\n",
    "svc = evalua(X, y_bin, SVC(), 10)\n",
    "decision_tree = evalua(X, y_bin, DecisionTreeClassifier(), 10)\n",
    "print(\"KNN -> Tasa de acierto {0:.4f}, Precision {1:.4f}, Recall {2:.4f}\".format(*k_neighbors))\n",
    "print(\"Regresión lineal -> Tasa de acierto {0:.4f}, Precision {1:.4f}, Recall {2:.4f}\".format(*logistic_regression))\n",
    "print(\"Random forest -> Tasa de acierto {0:.4f}, Precision {1:.4f}, Recall {2:.4f}\".format(*random_forest))\n",
    "print(\"SVC -> Tasa de acierto {0:.4f}, Precision {1:.4f}, Recall {2:.4f}\".format(*svc))\n",
    "print(\"Decision Tree -> Tasa de acierto {0:.4f}, Precision {1:.4f}, Recall {2:.4f}\".format(*decision_tree))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Desktop\\4UBU\\2 Semestre\\Mineria de datos\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN -> Tasa de acierto 0.5578, Precision 0.5185, Recall 0.5036\n",
      "Regresión lineal -> Tasa de acierto 0.8482, Precision 0.8550, Recall 0.8058\n",
      "Random forest -> Tasa de acierto 0.8350, Precision 0.8450, Recall 0.7842\n",
      "SVC -> Tasa de acierto 0.6436, Precision 0.6782, Recall 0.4245\n",
      "Decision Tree -> Tasa de acierto 0.7789, Precision 0.7647, Recall 0.7482\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 5. Análisis de resultados. (3 Puntos)<a id=\"5\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "-  Visualiza la matriz de confusión del mejor clasificador en terminos de recall, usa las predicciones que devuelve la función ``predicciones``.\n",
    "    - Para que quede bonito, puedes meter la matriz de confusión dentro de un DataFrame y puedes cambiar el nombre del índice y de las columnas.\n",
    "    \n",
    "    |             |   Sano (N) |   Enfermo (P) |\n",
    "    |:------------|-----------:|--------------:|\n",
    "    | Sano (N)    |        144 |            20 |\n",
    "    | Enfermo (P) |         29 |           110 |\n",
    "\n",
    "\n",
    "- Sabiendo que la ausencia de enfermedad es negativo y la presencia es positivo. \n",
    "    1. Obtén los True Positive, True Negatives, False Positives y False negatives usando una función.\n",
    "    2. Calcula precision como tp / (tp + fp)\n",
    "    3. Calcula recall como tp / (tp + fn)\n",
    "    4. Obtén comprueba que coinciden con los que te daba la función ``evalua``."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T16:25:19.214966Z",
     "start_time": "2025-02-27T16:25:18.774893Z"
    }
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "predicted = predicciones(X, y_bin, RandomForestClassifier(), 5)\n",
    "cnf_matrix = confusion_matrix(y_bin, predicted)\n",
    "class_names = (\"Sano(N)\",\"Enfermo(P)\")\n",
    "conf_mat_df = pd.DataFrame(cnf_matrix,\n",
    "                           index=class_names,\n",
    "                           columns=class_names)\n",
    "\n",
    "\n",
    "def obtencion(matriz):\n",
    "    TN = int((matriz[0])[0])\n",
    "    FN = int((matriz[0])[1])\n",
    "    FP = int((matriz[1])[0])\n",
    "    TP = int((matriz[1])[1])\n",
    "    return TP,TN,FP,FN\n",
    "\n",
    "resultado = obtencion(cnf_matrix)\n",
    "print (\"La cantidad de True positive es:\",resultado[0])\n",
    "print (\"La cantidad de True negative es:\",resultado[1])\n",
    "print (\"La cantidad de False positive es:\",resultado[2])\n",
    "print (\"La cantidad de False negative es:\",resultado[3])\n",
    "print (\"La precision obtenida es: \",resultado[0]/(resultado[0]+resultado[2]))\n",
    "print (\"El recall obtenido es: \",resultado[0]/(resultado[0]+resultado[3]))\n",
    "conf_mat_df"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de True positive es: 110\n",
      "La cantidad de True negative es: 138\n",
      "La cantidad de False positive es: 29\n",
      "La cantidad de False negative es: 26\n",
      "La precision obtenida es:  0.7913669064748201\n",
      "El recall obtenido es:  0.8088235294117647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            Sano(N)  Enfermo(P)\n",
       "Sano(N)         138          26\n",
       "Enfermo(P)       29         110"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sano(N)</th>\n",
       "      <th>Enfermo(P)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sano(N)</th>\n",
       "      <td>138</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enfermo(P)</th>\n",
       "      <td>29</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
